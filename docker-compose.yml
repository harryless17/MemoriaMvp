version: '3.8'

services:
  ml-worker:
    build: ./worker
    ports:
      - "8080:8080"
    env_file:
      - ./worker/.env
    environment:
      - WORKER_URL=http://ml-worker:8080
      - CLUSTER_EPSILON=0.55
      - MIN_CLUSTER_SIZE=2
    volumes:
      - ./worker:/app
    command: >
      sh -c "
        echo 'ðŸš€ Starting ML Worker...' &&
        uvicorn app.main:app --host 0.0.0.0 --port 8080 &
        echo 'ðŸ”„ Starting Job Poller...' &&
        python3 job_poller.py &
        wait
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Optional: Redis for job queue (future enhancement)
  # redis:
  #   image: redis:alpine
  #   ports:
  #     - "6379:6379"
  #   restart: unless-stopped
